# COEN 179 Theory of Algorithms 05_16_16

## Homeworks

    - FINAL TEST ON MONDAY
    - HOMEWORK 6 DUE FRIDAY, 5/27
      - DO FOR TEST ON MONDAY
    - HOMEWORK 7 DUE FRIDAY, 6/3
      - (optional, 4 best will be used)

## Project

    - Buffer N & Z
    - PC + X
    - LDPC
        - $rd <== PC + X
    - PC wrt value:
        - PC + 1
        - $rs
        - m[$rs]

## Memory Hierarchy

## Why Memory Hierarchy

    - Processor speed increasing faster than memory speed is increasing
    - Speed vs size conflict
    - Principle of locality
      - Program access a relative small portion of their address space --- if an item is referenced
      - temporal
        - will tend to be referenced again soon
      - spatial
        - nearby items will tend to be referenced soon
        - data shows spatial, not really temporal
    - 90/10 rule
      - 90% of the time, only 10% of the code is used
      - In your address space
      - Huge working space, but very small active space
      - Move that 10% into smaller but faster memory - cache
      - write code that shows locality
    - Goal of memory hierarchy, how it works
      - Speed of highest level (cache)
      - size of lowest level (disk)

## Terminology

    - How a processor access a memory hierarchy
      - access upper level first
      - if a miss, retrieve the whole block cointaining the requested data
    - Block (line) a set of consecutive words
    - Hit
    - Miss
    - Hit rate = #hits/#accesses
    - Miss penalty: time (transfer the block to upper level) + time (deliver data to processor)
      - from the book, on the order of 40 cycles
    - Why transfer the whole block?
      - take advantage of spacial locality
      - What is the size of the block?
      - Too small - higher miss rate
      - Too big - higher chance of miss

## Four Questions in Designing Memory hierarchy

    - Address mapping from lower level to upper level?
      - which place should it go?
    - How to find the requested data in the upper level?
      - address translation
      - probably most important
    - Which block to be replaced?
      - LRU, etc
      - Replacement policy
    - Write?
      - sw - write memory
      - how do you take care of multiple copies?
        - if in cache, it's in memory, possibly on disk etc
      - Write policy

## Cache: Interface between cache & main memory

    - 3 Different Caches
      - Direct mapped
        - RAM
      - Fully associative cache
        - no addresses
        - access by content
      - set associative cache
        - combination of the first two
    - "direct mapped"
      - for each item at the lower level, there is exactly one location in the cache where it might be
      - lots of items at the lower level share locations in the upper level
    - Direct and fully associative
      - different extremes

## Direct Mapped Cache

    - Mapping: address is modulo the number of blocks in the cache
    - cache size: 8
    - memory size: 32
    - 32/8 = 4 -> 4 memory words share same cache location
    - reduce chance of conflict
      - 3 least significant bits are the same
      - so that gives the cache index
      - matches with index in cache
    - 3 Points
      - How many memory locations share a cache location?
      - Don't have consecutive to share - locality
        - ask every 8 to share
      - lower 3 bits are the same, matches the cache interest
        - save the higher as the tag

## Cache with DMA

    - lower-order 3 bits of M. address = C. index
      - memory locations with the same lower-order 3 bits share the same cache location - due to to spatial locality
    - The block in cache to be replaced is fixed
      - can't go to any other spot
      - Replacement policy:
    - How do I know if the data is what I want?
      - tags: consist of higher-order bits of memory addresses
      - Compare the tags

## Format of a Word in Cache

    - | Valid | Tag | Data |
    - valid
      - = 1, valid address
      - = 0, this cache location is empty
    - Tag: remaining bits (higher order) of memory address
    - Ex:
      - mem size = 2^5
      - cache size = 2^3
      - tags: 5-3=2 bits
      - mem. addr: 01 001
        - 01 tag
        - 001 cache index
        - | 1 | 01 | mem[01001] |
    - When cpu accesses cache, check both valid and tag bits

## Example

| Decimal Address | Binary address | Hits/miss | Cache Index |
| 22              | 10110          |  m        | 110         |
| 26              | 11010          |  m        | 010         |
| 22              | 10110          |  h        | 110         |
| 18              | 10010          |  m        | 110         |
| 16              | 10000          |  M        | 000         |
| 18              | 10010          |
| 16              |
| 18              |

| Index | V    | Tag | data   |
| 000   | N->Y | 10  | m\[16] |
| 010   | N->Y | 11  | m\[26] | -> |010|y|10|m\[18]|
| 110   | N->Y | 10  | m\[22] |
|

    - Hit rate
      - 4/8 = 1/2

END
